I'm doing baby steps in scala and spark and Im facing an error that I'm not able to solve.

I'm trying map a csv file into DF, but is returning an error.

// Adding schema to RDDs - Initialization
``` scala
import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
import org.apache.spark.sql.Encoder
import spark.implicits._

case class Employee(name: String, age: Long)
val employeeDF = spark.sparkContext.textFile.("./employee.txt").map(_.split(",")).map(attributes => Employee(attributes(0), attributes(1).trim.toInt)).toDF()
employeeDF.createOrReplaceTempView("employee")

var youngstersDF = spark.sql("SELECT name,age FROM employee WHERE age BETWEEN 18 AND 30")
youngstersDF.map(youngster => "Name: " + youngster(0)).show()
```
When I try map the name returns an error as described below:

The error returned is:

``` scala
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 21, 192.168.0.122, executor driver): java.lang.NumberFormatException: For input string: "age"
```


The file content is: name,age John,28 Andrew,36 Clarke,22 Kevin,42

I googled it but no lucky in terms of solutions/answers.

Can someone please help?

With Many Thanks Xavy